{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvrGOsIgbmtrDmaJs3Qblx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieleduardofajardof/DataSciencePrepMaterial/blob/main/5_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5. Machine Learning\n",
        "\n",
        "#Index\n",
        "\n",
        "- [1. Supervised Learning](#one)\n",
        "- [2. Unsupervised Learning](#two)\n",
        "- [3. Evaluation Metrics](#three)\n",
        "- [4. Hyperparameter Optimization](#four)\n",
        "- [5. Optimization tecniques](#five)"
      ],
      "metadata": {
        "id": "xDhufUQbNDC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A comprehensive overview of machine learning algorithms, evaluation metrics, and optimization techniques.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Supervised Learning Algorithms <a name=\"one\"></a>\n",
        "\n",
        "Supervised learning uses labeled datasets to predict outcomes.\n",
        "\n",
        "\n",
        "### 1.1 Linear Regression\n",
        "\n",
        "- **Model**:  \n",
        "  $$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n + \\varepsilon $$\n",
        "- **Objective**: Minimize the Mean Squared Error (MSE):  \n",
        "  $$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
        "\n",
        "\n",
        "### 1.2 Logistic Regression\n",
        "\n",
        "- **Sigmoid Function**:  \n",
        "  $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
        "- **Model**:  \n",
        "  $$ P(y=1|X) = \\frac{1}{1 + e^{- (\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n)}} $$\n",
        "\n",
        "\n",
        "### 1.3 Tree-Based Methods\n",
        "\n",
        "#### 1.3.1 Decision Trees\n",
        "\n",
        "- Use recursive binary splitting based on metrics:\n",
        "  - **Gini Impurity**:  \n",
        "    $$ G = 1 - \\sum_{i=1}^{C} p_i^2 $$\n",
        "  - **Entropy**:  \n",
        "    $$ H = - \\sum_{i=1}^{C} p_i \\log_2 p_i $$\n",
        "\n",
        "\n",
        "### 1.4 Ensemble Techniques\n",
        "\n",
        "#### 1.4.1 Bagging (e.g., Random Forest)\n",
        "\n",
        "- Combines multiple models trained on bootstrap samples.\n",
        "- Reduces variance.\n",
        "\n",
        "#### 1.4.2 Boosting (e.g., XGBoost, AdaBoost)\n",
        "\n",
        "- Sequentially adds models to fix prior errors.\n",
        "- Reduces bias.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Unsupervised Learning Algorithms <a name=\"two\"></a>\n",
        "\n",
        "\n",
        "### 2.1 **K-Means Clustering**:\n",
        "- Partitions data into \\( K \\) clusters to minimize intra-cluster variance.\n",
        "- Objective function:  \n",
        "  $$ J = \\sum_{k=1}^{K} \\sum_{x_i \\in C_k} \\|x_i - \\mu_k\\|^2 $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 2.2 **Hierarchical Clustering**:\n",
        "- Builds a dendrogram (tree) using either:\n",
        "  - **Agglomerative** (bottom-up): Merges closest pairs\n",
        "  - **Divisive** (top-down): Splits until individual points\n",
        "- Distance metrics: Euclidean, Manhattan, Ward‚Äôs linkage, etc.\n",
        "\n",
        "\n",
        "### 2.3 **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**:\n",
        "- Groups points that are closely packed together (high density) and marks points in low-density regions as outliers.\n",
        "\n",
        "- **Key Concepts**:\n",
        "  - **Œµ (epsilon)**: Radius for neighborhood search\n",
        "  - **MinPts**: Minimum number of points to form a dense region\n",
        "  - **Core Point**: Has ‚â• MinPts in its Œµ-neighborhood\n",
        "  - **Border Point**: Not a core but reachable from a core\n",
        "  - **Noise Point**: Not reachable from any core point\n",
        "\n",
        "- **Advantages**:\n",
        "  - Can discover clusters of arbitrary shape\n",
        "  - Robust to outliers\n",
        "  - No need to specify the number of clusters\n",
        "\n",
        "- **Limitations**:\n",
        "  - Sensitive to the choice of Œµ and MinPts\n",
        "  - Struggles in varying density scenarios\n",
        "\n",
        "\n",
        "### 2.4 Dimensionality Reduction\n",
        "\n",
        "\n",
        "#### 2.4.1 **Principal Component Analysis (PCA)**:\n",
        "- Projects data onto orthogonal components capturing maximum variance.\n",
        "- Given data matrix \\( X \\):\n",
        "  $$ Z = XW $$\n",
        "  Where \\( W \\) is the matrix of top \\( k \\) eigenvectors of:\n",
        "  $$ \\Sigma = \\frac{1}{n} X^T X $$\n",
        "\n",
        "\n",
        "#### 2.4.2 **Singular Value Decomposition (SVD)**:\n",
        "- Matrix factorization technique:  \n",
        "  $$ X = U \\Sigma V^T $$\n",
        "- Useful in:\n",
        "  - Recommender systems\n",
        "  - Latent Semantic Analysis (text mining)\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Evaluation Metrics <a name=\"three\"></a>\n",
        "\n",
        "### 3.1 Classification\n",
        "\n",
        "- **Accuracy**:  \n",
        "  $$ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
        "\n",
        "- **Precision**:  \n",
        "  $$ \\text{Precision} = \\frac{TP}{TP + FP} $$\n",
        "\n",
        "- **Recall**:  \n",
        "  $$ \\text{Recall} = \\frac{TP}{TP + FN} $$\n",
        "\n",
        "- **F1 Score**:  \n",
        "  $$ F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n",
        "\n",
        "- **AUC**: Area under the ROC curve\n",
        "\n",
        "\n",
        "### 3.2 Regression\n",
        "- **MAE**:  \n",
        "  $$ \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $$\n",
        "\n",
        "- **MAPE**:  \n",
        "  $$ \\text{MAPE} = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| $$\n",
        "\n",
        "- **R¬≤ Score**:  \n",
        "  $$ R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}} $$\n",
        "\n",
        "- **Adjusted R¬≤**:  \n",
        "  $$ \\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - k - 1} \\right) $$  \n",
        "  where \\( k \\) = number of features, \\( n \\) = number of observations.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Hyperparameter Optimization <a name=\"four\"></a>\n",
        "\n",
        "### 4.1 Random Search\n",
        "\n",
        "- Randomly samples from a defined range of hyperparameters.\n",
        "\n",
        "### 4.2 Grid Search\n",
        "\n",
        "- Tries all combinations of hyperparameters from a predefined grid.\n",
        "\n",
        "### 4.3 Bayesian Optimization\n",
        "\n",
        "- Uses a surrogate model to estimate the objective function and chooses the next best parameter set.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_Dyv02XQPJtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5. Optimization Techniques <a name=\"five\"></a>\n",
        "\n",
        "### 5.1 Gradient Descent (GD)\n",
        "\n",
        "Gradient Descent is an **iterative optimization algorithm** used to find the minimum of a function. In Machine Learning, it's typically used to minimize the **loss function** of a model.\n",
        "\n",
        "\n",
        "### Concept\n",
        "\n",
        "Let $J(\\theta)$ be the loss (cost) function we want to minimize, where  $\\theta$ represents the model parameters (weights).\n",
        "\n",
        "At each iteration, parameters are updated using the **negative of the gradient**:\n",
        "\n",
        "$$\n",
        "\\theta := \\theta - \\alpha \\cdot \\nabla J(\\theta)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $\\theta $: parameter vector (weights)\n",
        "- $\\alpha$: learning rate (step size)\n",
        "- $\\nabla J(\\theta)$: gradient of the loss function with respect to $\\theta$\n",
        "\n",
        "\n",
        "\n",
        "### Why Use the Gradient?\n",
        "\n",
        "The gradient $\\nabla J(\\theta)$ points in the direction of the **steepest ascent**, so we move in the **opposite direction** to descend toward a local minimum.\n",
        "\n",
        "\n",
        "\n",
        "### Example: Linear Regression\n",
        "\n",
        "In linear regression, the cost function is the Mean Squared Error (MSE):\n",
        "\n",
        "$$\n",
        "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right)^2\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ m $: number of training examples\n",
        "- $h_\\theta(x) = \\theta^T x $: predicted value\n",
        "- $ y^{(i)}$): actual value\n",
        "\n",
        "Gradient of $J(\\theta)$:\n",
        "\n",
        "$$\n",
        "\\nabla J(\\theta) = \\frac{1}{m} X^T (X\\theta - y)\n",
        "$$\n",
        "\n",
        "Update rule:\n",
        "\n",
        "$$\n",
        "\\theta := \\theta - \\alpha \\cdot \\frac{1}{m} X^T (X\\theta - y)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "###  Learning Rate (Œ±)\n",
        "\n",
        "- **Too small**: Slow convergence\n",
        "- **Too large**: May overshoot or diverge\n",
        "\n",
        "A good strategy is to use **learning rate decay**:\n",
        "$$\n",
        "\\alpha_t = \\frac{\\alpha_0}{1 + \\text{decay\\_rate} \\cdot t}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### üîÑ Types of Gradient Descent\n",
        "\n",
        "| Type | Description | Pros | Cons |\n",
        "|------|-------------|------|------|\n",
        "| **Batch GD** | Uses entire dataset | Stable convergence | Slow for large datasets |\n",
        "| **Stochastic GD (SGD)** | One data point per step | Fast updates | Noisy updates |\n",
        "| **Mini-Batch GD** | Uses small random batches | Balance of speed and stability | Requires tuning batch size |\n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Extensions\n",
        "\n",
        "- **Momentum**:\n",
        "  Adds a velocity term to smooth updates:\n",
        "  $$\n",
        "  v_t = \\beta v_{t-1} + \\alpha \\nabla J(\\theta) \\\\\n",
        "  \\theta := \\theta - v_t\n",
        "  $$\n",
        "\n",
        "- **RMSProp**:\n",
        "  Uses a moving average of squared gradients to normalize learning rates:\n",
        "  $$\n",
        "  E[g^2]_t = \\gamma E[g^2]_{t-1} + (1 - \\gamma) g_t^2 \\\\\n",
        "  \\theta := \\theta - \\frac{\\alpha}{\\sqrt{E[g^2]_t + \\epsilon}} \\cdot g_t\n",
        "  $$\n",
        "\n",
        "- **Adam (Adaptive Moment Estimation)**:\n",
        "  Combines momentum and RMSProp:\n",
        "  $$\n",
        "  m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\\\\n",
        "  v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\\\\n",
        "  \\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\\\\n",
        "  \\theta := \\theta - \\alpha \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "### üèÅ Convergence Criteria\n",
        "\n",
        "- Gradient magnitude is small:  \n",
        "  $$ \\|\\nabla J(\\theta)\\| < \\epsilon $$\n",
        "- Small change in cost:  \n",
        "  $$ |J(\\theta_{t}) - J(\\theta_{t-1})| < \\delta $$\n",
        "- Max iterations reached\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Visualization\n",
        "\n",
        "If you imagine the loss function as a valley, gradient descent is like a ball rolling down the hill ‚Äî with the step size controlled by the learning rate.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Summary\n",
        "\n",
        "Gradient Descent is the backbone of many ML models, and mastering its variants (SGD, Adam, Momentum) is crucial for optimizing modern deep learning systems.\n",
        "\n",
        "---\n",
        "### 5.2 Backpropagation\n",
        "\n",
        "Backpropagation is the algorithm used to train artificial neural networks by adjusting weights using gradient descent. It efficiently computes the gradient of the **loss function** with respect to each weight in the network using the **chain rule of calculus**.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Why Backpropagation?\n",
        "\n",
        "In a neural network:\n",
        "- The **forward pass** computes the output.\n",
        "- The **backward pass** computes the **gradient of the loss** with respect to each weight.\n",
        "\n",
        "The gradients are then used to update the weights via **gradient descent**:\n",
        "$$\n",
        "w := w - \\alpha \\cdot \\frac{\\partial J}{\\partial w}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ w $: weight\n",
        "- $\\alpha $: learning rate\n",
        "- $ J $: loss function\n",
        "\n",
        "---\n",
        "\n",
        "### üèóÔ∏è Components of a Neural Network\n",
        "\n",
        "A typical layer computes:\n",
        "- **Linear transformation**:  \n",
        "  $$ z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]} $$\n",
        "- **Activation** (e.g., sigmoid, ReLU):  \n",
        "  $$ a^{[l]} = f(z^{[l]}) $$\n",
        "\n",
        "Where:\n",
        "- $ l $: layer index\n",
        "- $ W^{[l]} $: weight matrix for layer \\( l \\)\n",
        "- $ b^{[l]} $: bias vector\n",
        "- $ a^{[l]} $: activation (output) of layer \\( l \\)\n",
        "- $ a^{[0]} = X $: input features\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è Loss Function\n",
        "\n",
        "For binary classification, a common loss is **Binary Cross Entropy**:\n",
        "$$\n",
        "J = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ m $: number of examples\n",
        "- $ y^{(i)} $: true label\n",
        "- $ \\hat{y}^{(i)} $: predicted output from the final layer\n",
        "\n",
        "---\n",
        "\n",
        "### üîÅ The Backpropagation Steps\n",
        "\n",
        "#### Step 1: Compute Error at Output Layer\n",
        "Let $ L $ be the output layer:\n",
        "\n",
        "$$\n",
        "\\delta^{[L]} = \\frac{\\partial J}{\\partial a^{[L]}} \\cdot f'(z^{[L]})\n",
        "$$\n",
        "\n",
        "For MSE loss:\n",
        "$$\n",
        "\\delta^{[L]} = (a^{[L]} - y) \\cdot f'(z^{[L]})\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 2: Propagate Error Backward\n",
        "\n",
        "For hidden layers $ l = L-1, L-2, \\dots, 1 $:\n",
        "$$\n",
        "\\delta^{[l]} = \\left( W^{[l+1]^T} \\delta^{[l+1]} \\right) \\cdot f'(z^{[l]})\n",
        "$$\n",
        "\n",
        "This applies the **chain rule**.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 3: Compute Gradients\n",
        "\n",
        "- Gradient of weights:\n",
        "  $$\n",
        "  \\frac{\\partial J}{\\partial W^{[l]}} = \\delta^{[l]} {a^{[l-1]}}^T\n",
        "  $$\n",
        "- Gradient of biases:\n",
        "  $$\n",
        "  \\frac{\\partial J}{\\partial b^{[l]}} = \\delta^{[l]}\n",
        "  $$\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 4: Update Weights\n",
        "\n",
        "Apply gradient descent:\n",
        "$$\n",
        "W^{[l]} := W^{[l]} - \\alpha \\cdot \\frac{\\partial J}{\\partial W^{[l]}} \\\\\n",
        "b^{[l]} := b^{[l]} - \\alpha \\cdot \\frac{\\partial J}{\\partial b^{[l]}}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### üßÆ Example: 2-Layer Neural Network\n",
        "\n",
        "1. Forward pass:\n",
        "   - $z^{[1]} = W^{[1]} X + b^{[1]} $\n",
        "   - $ a^{[1]} = \\text{ReLU}(z^{[1]})$\n",
        "   - $ z^{[2]} = W^{[2]} a^{[1]} + b^{[2]} $\n",
        "   - $ \\hat{y} = \\sigma(z^{[2]}) $\n",
        "\n",
        "2. Backward pass:\n",
        "   - Compute $ \\delta^{[2]} = \\hat{y} - y $\n",
        "   - Compute $ \\delta^{[1]} = (W^{[2]^T} \\delta^{[2]}) \\cdot \\text{ReLU}'(z^{[1]}) $\n",
        "   - Compute gradients and update weights\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Summary\n",
        "\n",
        "- Backpropagation uses **chain rule** to compute gradients layer-by-layer.\n",
        "- It's efficient even for deep networks.\n",
        "- Works with any differentiable activation and loss function.\n",
        "\n",
        "---\n",
        "\n",
        "### üîÑ Extensions\n",
        "\n",
        "- Used with:\n",
        "  - **Stochastic Gradient Descent (SGD)**\n",
        "  - **Adam, RMSProp, Momentum**\n",
        "- Supported in frameworks like **TensorFlow**, **PyTorch**, and **JAX**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "x5nj_b1bRysk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oNxwhaYQOjB5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}