{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSV0bVbvILF7IdI5O2xYwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieleduardofajardof/DataSciencePrepMaterial/blob/main/6_AppliedML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6. Applied Machine Learning\n",
        "# Index\n",
        "\n",
        "\n",
        "- [1. Structured (Tabular) Data Analysis](#1)\n",
        "- [2. Predictive Analytics](#2)\n",
        "- [3. Anomaly Detection](#3)\n",
        "- [4. Behavioral Analysis](#4)\n",
        "- [5. Recommendation Systems](#5)\n",
        "- [6. Time Series Forecasting](#6)\n",
        "- [7. Customer Segmentation](#7)\n",
        "- [8. Inventory Management](#8)\n",
        "- [9. Pricing Optimization](#9)\n",
        "- [10. Image Classification](#10)\n",
        "- [11. Object Detection](#11)\n",
        "- [12. Semantic Segmentation](#12)\n",
        "- [13. Object Tracking](#13)\n",
        "- [14. Sentiment Analysis](#14)\n",
        "- [15. Named Entity Recognition](#15)\n",
        "- [16. Signal Data Preprocessing](#16)\n",
        "- [17. Markov Decision Process (MDP)](#17)\n",
        "- [18. Q-Learning](#18)"
      ],
      "metadata": {
        "id": "B_5JPioHmn91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Structured (Tabular) Data Analysis <a name=\"1\"></a>\n",
        "\n",
        "\n",
        "Tabular data is commonly found in spreadsheets and relational databases. Machine learning tasks on structured data include:\n",
        "\n",
        "- **Data Cleaning**: Handling missing values, outliers, duplicates.\n",
        "- **Feature Engineering**: Creating new features, encoding categorical variables, scaling.\n",
        "- **Modeling**: Classification (e.g., logistic regression, tree-based models) or regression (e.g., linear regression).\n",
        "- **Evaluation**: Metrics like accuracy, precision, recall, RMSE.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Predictive Analytics <a name=\"2\"></a>\n",
        "\n",
        "\n",
        "Predictive analytics involves using historical data to predict future outcomes:\n",
        "\n",
        "- **Input**: Historical features (sales, behavior, etc.)\n",
        "- **Output**: Predictions (churn probability, sales forecasts)\n",
        "- **Common models**: Linear regression, Random Forests, Gradient Boosting, Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Anomaly Detection <a name=\"3\"></a>\n",
        "\n",
        "\n",
        "Goal: Identify data points that deviate significantly from the norm.\n",
        "\n",
        "- **Techniques**:\n",
        "  - Statistical (Z-score, IQR)\n",
        "  - Clustering-based (DBSCAN)\n",
        "  - ML-based (Isolation Forest, Autoencoders)\n",
        "- **Applications**: Fraud detection, system monitoring, quality control\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Behavioral Analysis <a name=\"4\"></a>\n",
        "\n",
        "Analyzing patterns in user behavior to improve UX, target ads, or detect fraud.\n",
        "\n",
        "- **Features**: Clickstream data, time on site, action sequences\n",
        "- **Models**: Sequence models (RNNs), clustering, decision trees\n",
        "\n",
        "---\n",
        "\n",
        "## 5.  Recommendation Systems <a name=\"5\"></a>\n",
        "\n",
        "Sugg\n",
        "Suggest relevant items to users based on preferences:\n",
        "\n",
        "- **Collaborative Filtering**:\n",
        "  - Based on past user-item interactions (ratings, purchases)\n",
        "  - Two types: user-based and item-based collaborative filtering\n",
        "  - Common algorithm: Matrix Factorization (e.g., SVD)\n",
        "  - Predict missing entries in a user-item interaction matrix\n",
        "\n",
        "  $$\n",
        "  \\hat{r}_{ui} = p_u^T q_i\n",
        "  $$\n",
        "\n",
        "  where $p_u$ and $q_i$ are latent feature vectors for user $u$ and item $i$.\n",
        "\n",
        "- **Content-Based Filtering**:\n",
        "  - Uses features of the items (genre, description, etc.)\n",
        "  - Recommends items similar to those the user liked before\n",
        "  - Measures similarity (e.g., cosine similarity) between item vectors\n",
        "\n",
        "  $$\n",
        "  \\text{sim}(i, j) = \\frac{\\vec{x}_i \\cdot \\vec{x}_j}{\\|\\vec{x}_i\\| \\|\\vec{x}_j\\|}\n",
        "  $$\n",
        "\n",
        "- **Hybrid Methods**:\n",
        "  - Combine collaborative and content-based approaches\n",
        "  - Example strategies:\n",
        "    - Weighted hybrid: blend scores from multiple models\n",
        "    - Switching hybrid: choose method based on context or data\n",
        "    - Mixed hybrid: recommend from both models simultaneously\n",
        "\n",
        "**Metrics**:\n",
        "- **Precision@K**: Fraction of top-K recommended items that are relevant\n",
        "- **Recall@K**: Fraction of all relevant items captured in top-K recommendations\n",
        "- **NDCG (Normalized Discounted Cumulative Gain)**: Measures ranking quality while accounting for the position of relevant items\n",
        "\n",
        "$$\n",
        "\\text{DCG@K} = \\sum_{i=1}^{K} \\frac{rel_i}{\\log_2(i + 1)}, \\quad \\text{NDCG@K} = \\frac{\\text{DCG@K}}{\\text{IDCG@K}}\n",
        "$$\n",
        "\n",
        "Where $rel_i$ is the relevance score of the item at position $i$, and IDCG is the ideal DCG (perfect ranking).\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Time Series Forecasting <a name=\"6\"></a>\n",
        "\n",
        "Predict future values from past data points. Time series forecasting is crucial for decision-making in domains where temporal patterns exist.\n",
        "\n",
        "- **Characteristics**:\n",
        "  - Observations are sequentially ordered in time\n",
        "  - May exhibit trend, seasonality, cyclic behavior, and noise\n",
        "\n",
        "- **Classical Models**:\n",
        "  - **ARIMA (AutoRegressive Integrated Moving Average)**: Combines autoregression (AR), differencing (I), and moving average (MA)\n",
        "\n",
        "    $$\n",
        "    y_t = c + \\phi_1 y_{t-1} + \\dots + \\phi_p y_{t-p} + \\theta_1 \\epsilon_{t-1} + \\dots + \\theta_q \\epsilon_{t-q} + \\epsilon_t\n",
        "    $$\n",
        "\n",
        "  - **SARIMA**: Extension of ARIMA that incorporates seasonal components:\n",
        "    \n",
        "    $$\n",
        "    SARIMA(p,d,q)(P,D,Q)_s\n",
        "    $$\n",
        "\n",
        "    where \\( s \\) is the seasonal period (e.g., 12 for monthly data with yearly seasonality).\n",
        "\n",
        "- **Modern Models**:\n",
        "  - **Prophet**: Developed by Facebook, decomposes time series into trend, seasonality, and holiday effects using additive models.\n",
        "  - **LSTM (Long Short-Term Memory)**: A type of recurrent neural network (RNN) that handles long-range dependencies in sequential data.\n",
        "  - **Transformer-based models**: Use self-attention mechanisms to model temporal dependencies and perform well on long sequences.\n",
        "\n",
        "- **Applications**:\n",
        "  - Sales forecasting\n",
        "  - Stock price prediction\n",
        "  - Energy consumption prediction\n",
        "  - Weather prediction\n",
        "  - Resource allocation\n",
        "  - Demand planning\n",
        "\n",
        "- **Evaluation Metrics**:\n",
        "  - **MAE (Mean Absolute Error)**: $ MAE = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i| $\n",
        "  - **RMSE (Root Mean Square Error)**: $ RMSE = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 } $\n",
        "  - **MAPE (Mean Absolute Percentage Error)**: $ MAPE = \\frac{100\\%}{n} \\sum_{i=1}^n \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| $\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ln_ucJzOnc9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7. Customer Segmentation <a name=\"7\"></a>\n",
        "\n",
        "Customer segmentation is the practice of dividing customers into groups based on shared characteristics or behaviors. This helps businesses better understand their audience and make informed decisions across marketing, sales, and product development.\n",
        "\n",
        "### Techniques\n",
        "\n",
        "Several clustering algorithms can be used for segmentation:\n",
        "\n",
        "- K-Means: Groups customers into a predefined number of clusters based on similarity.\n",
        "- DBSCAN: Identifies dense regions of customers and marks outliers as noise.\n",
        "- Hierarchical Clustering: Builds a tree of clusters, allowing flexibility in choosing the number of segments.\n",
        "\n",
        "### Features\n",
        "\n",
        "Segmentation is often based on customer activity data. A common framework is RFM:\n",
        "\n",
        "- Recency: How recently a customer made a purchase.\n",
        "- Frequency: How often they purchase.\n",
        "- Monetary: How much money they spend.\n",
        "\n",
        "Additional features may include demographics, browsing history, and product preferences.\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "Customer segmentation supports a range of business goals:\n",
        "\n",
        "- Targeted marketing: Deliver personalized campaigns to specific segments.\n",
        "- Churn prediction: Identify customers at risk of leaving.\n",
        "- Product recommendations: Suggest items based on customer group behavior.\n",
        "- Customer lifetime value prediction: Focus resources on high-value segments.\n",
        "\n",
        "---\n",
        "## 8. Inventory Management <a name=\"8\"></a>\n",
        "\n",
        "Inventory management is the process of efficiently overseeing the flow of goods in and out of storage to ensure the right products are available at the right time, in the right quantity. The goal is to meet customer demand while minimizing the costs of holding excess inventory or running out of stock.\n",
        "\n",
        "Effective inventory management helps businesses reduce storage costs, avoid stockouts, improve cash flow, and increase customer satisfaction. It requires balancing supply and demand through careful planning and data analysis.\n",
        "\n",
        "#### Tasks\n",
        "\n",
        "Key tasks involved in inventory management include:\n",
        "\n",
        "- Demand forecasting: Predicting future customer demand using historical sales data, seasonality patterns, and market trends.\n",
        "- Safety stock calculation: Determining the minimum amount of extra stock to keep on hand as a buffer against uncertainties in demand or supply delays.\n",
        "- Reorder point prediction: Calculating the inventory level at which a new order should be placed to avoid running out of stock before the replenishment arrives.\n",
        "\n",
        "#### Models\n",
        "\n",
        "Several types of models are used to support inventory management decisions:\n",
        "\n",
        "- Time series models: Use past data to predict future demand. Examples include ARIMA, exponential smoothing, and seasonal decomposition.\n",
        "- Probabilistic models: Account for uncertainty in demand and lead time using statistical distributions to estimate optimal stock levels and reorder points.\n",
        "\n",
        "By combining data-driven models with inventory best practices, businesses can maintain optimal stock levels, reduce waste, and respond more flexibly to changes in market demand.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Pricing Optimization <a name=\"9\"></a>\n",
        "\n",
        "Pricing optimization is the process of using data and machine learning techniques to determine the best prices for products or services in order to maximize revenue, profit, or market competitiveness. Rather than relying on static pricing strategies or gut instinct, pricing optimization relies on data-driven approaches that adapt to customer behavior, market trends, and competitor pricing.\n",
        "\n",
        "The goal is to find a balance between price and demand—charging enough to increase profitability while still remaining attractive to customers.\n",
        "\n",
        "### Approaches\n",
        "\n",
        "There are several machine learning and statistical approaches used in pricing optimization:\n",
        "\n",
        "- Demand elasticity modeling: This involves estimating how sensitive customer demand is to changes in price. By understanding the relationship between price and demand, businesses can predict how a price change might affect sales volume and revenue.\n",
        "\n",
        "- A/B testing: Companies test different price points with different customer groups to directly observe the impact on conversion rates, sales, or profit. This experimental approach provides real-world feedback on pricing strategies.\n",
        "\n",
        "- Reinforcement learning for dynamic pricing: This technique uses trial-and-error learning to adjust prices over time based on ongoing results. The model continuously updates its pricing policy to maximize long-term rewards, adapting to changing market conditions and customer behavior.\n",
        "\n",
        "### Benefits\n",
        "\n",
        "Implementing pricing optimization can lead to:\n",
        "\n",
        "- Increased revenue and profit margins\n",
        "- Better customer segmentation and personalized pricing\n",
        "- Improved competitiveness in the market\n",
        "- Faster adaptation to seasonal trends or market changes\n",
        "\n",
        "Pricing optimization is widely used in industries like e-commerce, airlines, hospitality, ride-sharing, and subscription services, where small price changes can have a big impact on business outcomes.\n",
        "\n"
      ],
      "metadata": {
        "id": "ysClGGaXo7Kz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## **Computer Vision**\n",
        "\n",
        "## 10. Image Classification <a name=\"10\"></a>\n",
        "\n",
        "Image classification is a computer vision task where the goal is to assign a single label or category to an entire image. This means analyzing the visual content of the image and determining what object, scene, or concept it represents. It is one of the most fundamental tasks in image-based machine learning and serves as the foundation for many more advanced applications.\n",
        "\n",
        "Image classification systems are trained on labeled datasets, where each image is associated with a known class. During training, the model learns to recognize patterns, textures, shapes, and features that distinguish one class from another.\n",
        "\n",
        "### Models\n",
        "\n",
        "Convolutional Neural Networks (CNNs) are the most widely used models for image classification. They are specifically designed to process grid-like data, such as images, by applying filters that capture spatial hierarchies of features.\n",
        "\n",
        "Popular CNN architectures include:\n",
        "\n",
        "- ResNet (Residual Network): A deep network that uses skip connections to allow gradients to flow through deeper layers without vanishing.\n",
        "- VGG (Visual Geometry Group): A simpler architecture known for using small 3x3 filters and a uniform layer structure.\n",
        "- Inception, MobileNet, EfficientNet: Other architectures optimized for speed, accuracy, or deployment on edge devices.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "Image classification is used in a wide variety of domains and applications. Common tasks include:\n",
        "\n",
        "- Digit recognition: Classifying handwritten digits, such as in the MNIST dataset, which is often used for educational and benchmarking purposes.\n",
        "- Medical image classification: Identifying diseases or abnormalities from medical images like X-rays, MRIs, or skin lesion photos.\n",
        "- Object presence detection: Determining whether an object, like a cat or car, is present in an image.\n",
        "- Scene classification: Categorizing images based on environments, such as beaches, forests, or urban settings.\n",
        "\n",
        "### Summary\n",
        "\n",
        "By accurately classifying images, models can automate tasks that would otherwise require human visual inspection. Image classification plays a critical role in areas such as healthcare, security, autonomous vehicles, and content moderation.\n",
        "---\n",
        "## 11. Object Detection <a name=\"11\"></a>\n",
        "\n",
        "Object detection is a computer vision task that involves both identifying (classifying) and locating (detecting) multiple objects within a single image. Unlike image classification, which assigns a single label to an entire image, object detection provides both the class label and the position (bounding box) of each object present in the image.\n",
        "\n",
        "The output of an object detection model typically includes:\n",
        "- The class of each detected object (e.g., person, car, dog)\n",
        "- The bounding box coordinates that define where each object is located\n",
        "- A confidence score indicating how certain the model is about each prediction\n",
        "\n",
        "### Models\n",
        "\n",
        "Several deep learning models have been developed specifically for object detection, each with different trade-offs in speed and accuracy:\n",
        "\n",
        "- YOLO (You Only Look Once): A fast and efficient model that performs detection in a single forward pass. Suitable for real-time applications such as autonomous driving and video surveillance.\n",
        "\n",
        "- SSD (Single Shot MultiBox Detector): Similar in principle to YOLO, SSD detects objects in one pass but uses multiple feature maps to handle objects at different scales.\n",
        "\n",
        "- Faster R-CNN: A two-stage detector that first proposes regions of interest and then classifies them. Known for high accuracy but typically slower than single-shot detectors.\n",
        "\n",
        "### Applications\n",
        "\n",
        "Object detection is used in a wide range of real-world scenarios, including:\n",
        "\n",
        "- Autonomous vehicles: Detecting pedestrians, other vehicles, traffic signs, and obstacles.\n",
        "- Retail: Monitoring inventory, customer movement, or product placement.\n",
        "- Security and surveillance: Identifying intruders, weapons, or suspicious objects in real-time.\n",
        "- Healthcare: Detecting anomalies or features in medical images, such as tumors or organs.\n",
        "- Robotics: Enabling robots to understand and interact with their environment by recognizing and locating objects.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Object detection combines the challenges of classification and localization into a single task. Modern deep learning models have made it possible to perform object detection accurately and in real-time, enabling a wide range of intelligent visual applications.\n",
        "---\n",
        "## 12.  Semantic Segmentation <a name=\"12\"></a>\n",
        "\n",
        "Semantic segmentation is a computer vision task that involves classifying each pixel in an image into a specific category. Unlike image classification, which assigns a single label to the whole image, or object detection, which identifies and localizes objects with bounding boxes, semantic segmentation provides a much more fine-grained understanding of the image by labeling every pixel.\n",
        "\n",
        "The result is a segmented image where all pixels belonging to the same class (such as \"road\", \"sky\", \"person\", \"tree\") are grouped together and distinguished from other classes. This pixel-level prediction is especially useful in tasks where spatial precision is critical.\n",
        "\n",
        "### Models\n",
        "\n",
        "Several deep learning architectures are designed specifically for semantic segmentation:\n",
        "\n",
        "- U-Net: Originally developed for biomedical image segmentation, U-Net uses an encoder-decoder structure with skip connections that help preserve spatial information during upsampling. It performs well even with limited data.\n",
        "\n",
        "- DeepLab: A family of models (e.g., DeepLabv3, DeepLabv3+) that use atrous (dilated) convolutions to capture multi-scale context and improve segmentation accuracy. DeepLab also uses techniques like Conditional Random Fields (CRFs) to refine boundaries between different classes.\n",
        "\n",
        "Other notable models include FCN (Fully Convolutional Networks), SegNet, and PSPNet.\n",
        "\n",
        "### Applications\n",
        "\n",
        "Semantic segmentation has a wide range of applications, including:\n",
        "\n",
        "- Autonomous driving: Understanding the scene by identifying roads, vehicles, pedestrians, traffic signs, and other elements.\n",
        "- Medical imaging: Segmenting organs, tumors, or other anatomical structures in scans like MRIs or CTs.\n",
        "- Satellite imagery: Classifying land cover types such as water, forest, urban areas, or crops.\n",
        "- Augmented reality: Enabling background removal or enhancing user interaction by precisely identifying regions in a scene.\n",
        "- Robotics: Assisting in object manipulation and scene understanding by segmenting objects and surfaces.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Semantic segmentation provides detailed visual understanding by assigning a class label to every pixel in an image. It is a key technology in fields that require precise image analysis and has seen significant advances through deep learning-based models like U-Net and DeepLab.\n"
      ],
      "metadata": {
        "id": "566RcyX7p6mL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 13. Object Tracking <a name=\"13\"></a>\n",
        "\n",
        "Object tracking is a computer vision task that involves following the movement of one or more objects across video frames. The goal is to maintain a consistent identity for each object as it moves, appears, disappears, or interacts with other objects over time. Unlike object detection, which works on single images, tracking focuses on the temporal continuity of objects.\n",
        "\n",
        "Object tracking systems usually start with object detection to locate instances in the current frame and then use tracking algorithms to associate those detections with existing object tracks from previous frames.\n",
        "\n",
        "### Algorithms\n",
        "\n",
        "Several algorithms are commonly used for object tracking, each with its strengths depending on the complexity of the scene and tracking requirements:\n",
        "\n",
        "- SORT (Simple Online and Realtime Tracking): A lightweight and fast tracking algorithm that combines object detection with the Kalman filter for motion prediction and the Hungarian algorithm for data association. Suitable for real-time applications but limited in handling occlusions or re-identification.\n",
        "\n",
        "- Deep SORT: An extension of SORT that incorporates deep learning-based appearance descriptors to better distinguish between similar-looking objects. This allows it to handle occlusions and object re-identification more effectively.\n",
        "\n",
        "- Kalman Filters: A mathematical approach used to estimate the future state (position and velocity) of an object based on noisy observations. Often used in combination with detection algorithms to maintain smooth and robust tracks.\n",
        "\n",
        "Other tracking methods include optical flow, particle filters, and transformer-based models for more complex tracking scenarios.\n",
        "\n",
        "### Applications\n",
        "\n",
        "Object tracking is widely used in various real-world applications:\n",
        "\n",
        "- Video surveillance: Tracking people or vehicles across camera footage for security and analysis.\n",
        "- Autonomous vehicles: Monitoring pedestrians, cars, and other dynamic objects to make real-time driving decisions.\n",
        "- Sports analytics: Following players or balls to extract statistics and create visualizations.\n",
        "- Augmented reality: Anchoring digital content to moving physical objects in real time.\n",
        "- Human-computer interaction: Tracking hand or body movements for gesture recognition and control systems.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Object tracking builds on object detection by maintaining the identity and trajectory of objects across multiple frames in a video. With efficient algorithms like SORT and Deep SORT, tracking has become a key component in real-time systems such as surveillance, robotics, and autonomous vehicles.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "## Natural Language Processing (NLP)\n",
        "\n",
        "## 14. Sentiment Analysis <a name=\"14\"></a>\n",
        "\n",
        "Determine the sentiment (positive/negative/neutral) of text.\n",
        "\n",
        "- **Techniques**: Rule-based, Naive Bayes, LSTM, BERT\n",
        "\n",
        "### Topic Modeling\n",
        "\n",
        "Topic modeling is an unsupervised machine learning technique used to discover the hidden thematic structure in a large collection of documents. It helps in identifying groups of words (topics) that frequently occur together and provides insight into the main themes present across a corpus without requiring labeled data.\n",
        "\n",
        "Each document can be associated with multiple topics in varying proportions, and each topic is characterized by a distribution over words. This makes topic modeling particularly useful for organizing, summarizing, and understanding large volumes of unstructured text data.\n",
        "\n",
        "### Algorithms\n",
        "\n",
        "Several algorithms are commonly used for topic modeling:\n",
        "\n",
        "- **LDA (Latent Dirichlet Allocation)**: One of the most popular and widely used topic modeling methods. LDA assumes that each document is a mixture of topics and each topic is a distribution over words. It uses probabilistic modeling to infer the underlying topic structure and has been successful across various domains.\n",
        "\n",
        "- **NMF (Non-negative Matrix Factorization)**: A linear algebra-based method that factorizes the document-term matrix into two non-negative matrices—one representing topic-word associations and the other document-topic associations. NMF is known for producing more interpretable results and can be faster than LDA on some datasets.\n",
        "\n",
        "Other approaches like BERTopic (based on BERT embeddings and clustering) and CorEx (Correlation Explanation) are also gaining popularity for advanced and context-aware topic modeling.\n",
        "\n",
        "### Applications\n",
        "\n",
        "Topic modeling has a wide range of applications, including:\n",
        "\n",
        "- Text summarization: Extracting dominant themes from large text corpora.\n",
        "- Content recommendation: Grouping similar articles or documents by topic.\n",
        "- Document classification: Using inferred topics as features for downstream classification tasks.\n",
        "- Trend analysis: Discovering how topics evolve over time in news, social media, or academic literature.\n",
        "- Customer feedback analysis: Identifying common themes in survey responses or reviews.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Topic modeling provides a powerful way to explore and organize text data by uncovering latent semantic structures. With algorithms like LDA and NMF, it enables automatic theme extraction, making it invaluable for tasks involving large-scale document analysis.\n",
        "\n",
        "---\n",
        "\n",
        "## 15. Named Entity Recognition (NER) <a name=\"15\"></a>\n",
        "\n",
        "Named Entity Recognition (NER) is a Natural Language Processing (NLP) task that involves identifying and categorizing key pieces of information—called entities—within a text. These entities typically include names of people, organizations, locations, dates, numerical values, and more.\n",
        "\n",
        "The goal of NER is not just to locate these entities in the text but also to classify them into predefined categories such as:\n",
        "\n",
        "- Person (e.g., \"Barack Obama\")\n",
        "- Organization (e.g., \"United Nations\")\n",
        "- Location (e.g., \"Paris\")\n",
        "- Date/Time (e.g., \"April 6, 2025\")\n",
        "- Miscellaneous (e.g., product names, events, etc.)\n",
        "\n",
        "NER is often one of the foundational steps in information extraction, helping convert unstructured text into structured data.\n",
        "\n",
        "### Models\n",
        "\n",
        "Several models are commonly used to perform NER:\n",
        "\n",
        "- **CRF (Conditional Random Fields)**: A statistical model that considers the sequence structure of text, making it effective for labeling tasks like NER. CRFs work well with handcrafted features but can be limited in scalability.\n",
        "\n",
        "- **BiLSTM-CRF (Bidirectional Long Short-Term Memory with CRF)**: This model combines deep learning with sequence modeling. The BiLSTM captures contextual information from both directions in the text, and the CRF layer ensures globally optimal sequence labeling.\n",
        "\n",
        "- **Transformer-based Models (e.g., BERT)**: Pretrained language models like BERT have significantly advanced the state of the art in NER. They provide contextual embeddings for each word based on the entire sentence, enabling highly accurate entity recognition even in complex contexts.\n",
        "\n",
        "### Applications\n",
        "\n",
        "NER is widely used in both academic research and industry applications, such as:\n",
        "\n",
        "- **Information retrieval**: Enhancing search engines by indexing entities.\n",
        "- **Chatbots and virtual assistants**: Understanding user inputs to identify relevant entities (e.g., cities, names, dates).\n",
        "- **Document classification and summarization**: Highlighting key entities to improve downstream processing.\n",
        "- **Financial and legal analysis**: Extracting names of companies, financial figures, and legal entities from dense documents.\n",
        "- **Healthcare**: Identifying medications, symptoms, and patient information in clinical text.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Named Entity Recognition enables systems to extract meaningful information from raw text by identifying and classifying important entities. With the rise of deep learning and transformer models like BERT, NER systems have become more accurate and robust, making them essential tools in modern NLP pipelines.\n",
        "\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "y7pebPrTp6pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Signal / Audio Processing**\n",
        "\n",
        "## 16. Signal Data Preprocessing <a name=\"16\"></a>\n",
        "\n",
        "Signal data preprocessing is a crucial step in preparing raw sensor or time-series data for analysis or modeling. This process ensures that the signal is clean, consistent, and represented in a way that models can understand. Preprocessing helps improve the quality and performance of downstream tasks such as classification, regression, or anomaly detection.\n",
        "\n",
        "Key steps involved in signal preprocessing include:\n",
        "\n",
        "#### Framing\n",
        "Framing involves dividing a continuous signal into short, overlapping segments (frames). This is especially useful for non-stationary signals (e.g., audio, physiological signals) where the characteristics may vary over time. Overlapping windows help preserve temporal continuity and capture transitions in the signal.\n",
        "\n",
        "- Example: Splitting a 10-second audio clip into 25ms frames with 10ms overlap.\n",
        "- Common window functions: Hamming, Hann, or rectangular.\n",
        "\n",
        "#### Aggregation\n",
        "Once the signal is framed, statistical or domain-specific features are extracted from each frame. Aggregation summarizes the information and reduces dimensionality.\n",
        "\n",
        "Typical aggregation methods include:\n",
        "- **Mean**: Average signal value per frame\n",
        "- **Max/Min**: Captures peak behavior or sudden spikes\n",
        "- **Standard Deviation (std)**: Measures variability or intensity of the signal\n",
        "- **Energy, Zero-crossing rate, Spectral features** (depending on domain)\n",
        "\n",
        "These features serve as input to machine learning models for tasks like emotion recognition, fault detection, or activity classification.\n",
        "\n",
        "#### Outlier Handling\n",
        "Raw signals often contain noise or outliers that can negatively impact analysis. Outlier handling methods help smooth the signal and make it more robust:\n",
        "\n",
        "- **Smoothing**: Techniques like moving average, Gaussian filter, or Savitzky-Golay filter reduce noise while preserving trends.\n",
        "- **Winsorization**: Caps extreme values at a specific percentile threshold to limit their influence.\n",
        "- **Clipping or interpolation**: Can be used for sudden spikes or missing values.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Signal data preprocessing transforms noisy, continuous signals into structured and informative features. By framing, aggregating, and handling outliers effectively, we enable more accurate and stable analysis, especially in domains like audio processing, biomedical signals, and industrial monitoring.\n",
        "---\n",
        "---\n",
        "## **Reinforcement Learning**\n",
        "\n",
        "## 17. Markov Decision Process (MDP) <a name=\"17\"></a>\n",
        "\n",
        "A Markov Decision Process (MDP) is a mathematical framework used to describe decision-making in environments where outcomes are partly random and partly under the control of a decision-maker. MDPs are widely used in reinforcement learning, operations research, robotics, and control systems.\n",
        "\n",
        "An MDP provides a formalization for sequential decision problems and is defined by the following components:\n",
        "\n",
        "- **S (Set of States)**: Represents all possible states the environment can be in. For example, in a grid-world environment, each cell is a different state.\n",
        "\n",
        "- **A (Set of Actions)**: The set of all possible actions an agent can take in a given state. The available actions may depend on the current state.\n",
        "\n",
        "- **P(s' | s, a) (Transition Probability Function)**: Describes the probability of transitioning to a new state `s'` when action `a` is taken in state `s`. This function captures the dynamics of the environment.\n",
        "\n",
        "- **R(s, a) (Reward Function)**: Defines the immediate reward received after taking action `a` in state `s`. Rewards guide the agent toward desirable behavior.\n",
        "\n",
        "- **γ (Gamma, Discount Factor)**: A value between 0 and 1 that determines the importance of future rewards. A γ close to 0 makes the agent short-sighted (focusing on immediate rewards), while a γ close to 1 encourages long-term planning.\n",
        "\n",
        "### Objective\n",
        "\n",
        "The goal of an agent in an MDP is to find a **policy** π(s) that defines the best action to take in each state in order to **maximize the expected cumulative reward** (also known as the return) over time.\n",
        "\n",
        "The cumulative reward is often defined as:\n",
        "\n",
        "$$ G_t = R(s_t, a_t) + γ * R(s_{t+1}, a_{t+1}) + γ² * R(s_{t+2}, a_{t+2}) + ...$$\n",
        "\n",
        "\n",
        "### Applications\n",
        "\n",
        "- Reinforcement learning (e.g., Q-learning, policy gradient methods)\n",
        "- Game AI and planning\n",
        "- Autonomous robotics and navigation\n",
        "- Finance and inventory management\n",
        "\n",
        "### Summary\n",
        "\n",
        "Markov Decision Processes provide the foundational structure for decision-making under uncertainty. By modeling the states, actions, transitions, rewards, and future value, MDPs enable intelligent agents to learn optimal strategies in complex, dynamic environments.\n",
        "\n",
        "---\n",
        "## 18. Q-Learning <a name=\"18\"></a>\n",
        "\n",
        "Q-Learning is a **model-free reinforcement learning** algorithm that learns the optimal action-value function, denoted as Q(s, a), without requiring knowledge of the environment’s dynamics (i.e., transition probabilities).\n",
        "\n",
        "The Q-function estimates the expected cumulative reward of taking action `a` in state `s`, and then following the optimal policy thereafter.\n",
        "\n",
        "The Q-values are updated iteratively using the following rule:\n",
        "\n",
        "$$\n",
        "Q(s, a) := Q(s, a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s, a) \\right]\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $Q(s, a)$: Current estimate of the Q-value for state-action pair\n",
        "- $\\alpha$: Learning rate (controls how much new information overrides old)\n",
        "- $r$: Reward received after taking action $a$ in state $s$\n",
        "- $\\gamma$: Discount factor (determines importance of future rewards)\n",
        "- $s'$: Next state after taking action $a$\n",
        "- $\\max_{a'} Q(s', a')$: Estimated value of the best next action in the next state\n",
        "\n",
        "Q-Learning is an **off-policy** algorithm, meaning it learns the value of the optimal policy independently of the agent's actions during training (e.g., it may use exploratory policies like $\\epsilon$-greedy).\n",
        "\n",
        "\n",
        "\n",
        "### Reward and Policy Optimization\n",
        "\n",
        "The ultimate objective in reinforcement learning is to **maximize cumulative reward** by learning a good policy—a mapping from states to actions.\n",
        "\n",
        "There are two broad approaches for learning optimal policies:\n",
        "\n",
        "#### Policy Gradient Methods\n",
        "These methods directly optimize the policy function (often parameterized by a neural network). They use gradient ascent to maximize the expected reward. This is especially useful in continuous or high-dimensional action spaces.\n",
        "\n",
        "- Examples: REINFORCE, PPO (Proximal Policy Optimization), DDPG\n",
        "\n",
        "#### Actor-Critic Methods\n",
        "Actor-Critic architectures combine two components:\n",
        "- **Actor**: Learns the policy (i.e., how to act)\n",
        "- **Critic**: Learns the value function (i.e., how good an action is)\n",
        "\n",
        "The actor updates its policy using feedback from the critic. This setup offers a good trade-off between variance and bias, and improves training stability.\n",
        "\n",
        "\n",
        "\n",
        "### Applications\n",
        "\n",
        "Reinforcement learning algorithms, especially Q-Learning and policy gradient methods, are used in a variety of real-world and research scenarios:\n",
        "\n",
        "- **Robotics**: Learning control policies for robotic arms or autonomous vehicles\n",
        "- **Finance**: Training trading agents to make investment decisions\n",
        "- **Gaming**: Mastering games like Go (AlphaGo), Chess, and video games (DQN for Atari)\n",
        "\n",
        "\n",
        "\n",
        "### Summary\n",
        "\n",
        "Q-Learning is a foundational method in RL that learns optimal behaviors through trial and error. Policy gradient and actor-critic methods extend these ideas to more complex environments, enabling intelligent agents to operate in real-time, high-dimensional settings.\n"
      ],
      "metadata": {
        "id": "rhvaSzzap6r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WwvJFr9Np6ud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SG9MCQQBp6wg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNWclf_0p5z_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}